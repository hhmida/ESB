{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0de2lf2DZgzDjEMyxwoSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhmida/ESB/blob/main/Application_SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKFTEElLFwQ2",
        "outputId": "14b92997-b24e-41f1-da47-2e48139e24ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 09:07:56--  https://hhmida.github.io/tp-hadoop-iset/assets/credit_risk_dataset.csv\n",
            "Resolving hhmida.github.io (hhmida.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to hhmida.github.io (hhmida.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1804682 (1.7M) [text/csv]\n",
            "Saving to: ‘credit_risk_dataset.csv’\n",
            "\n",
            "\rcredit_risk_dataset   0%[                    ]       0  --.-KB/s               \rcredit_risk_dataset 100%[===================>]   1.72M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-12-02 09:07:56 (228 MB/s) - ‘credit_risk_dataset.csv’ saved [1804682/1804682]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://hhmida.github.io/tp-hadoop-iset/assets/credit_risk_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQbHq6VMF7iC",
        "outputId": "ffb6972a-75a7-40a2-99b7-9d0651bf73d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 53 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 66.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=a3d32269970a174a6cd1319e144653752e11e6e9950352a17075ff8d6beab5b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Exercice SparkSQL').getOrCreate()"
      ],
      "metadata": {
        "id": "YcBCCYodF-jV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits = spark.read.csv(\"credit_risk_dataset.csv\", header=True).cache()"
      ],
      "metadata": {
        "id": "r-siXFO6GRo5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3vSK3KsGj2P",
        "outputId": "ad3c1757-35f8-4d9c-da8c-53d8d80c5132"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- person_age: string (nullable = true)\n",
            " |-- person_income: string (nullable = true)\n",
            " |-- person_home_ownership: string (nullable = true)\n",
            " |-- person_emp_length: string (nullable = true)\n",
            " |-- loan_intent: string (nullable = true)\n",
            " |-- loan_grade: string (nullable = true)\n",
            " |-- loan_amnt: string (nullable = true)\n",
            " |-- loan_int_rate: string (nullable = true)\n",
            " |-- loan_status: string (nullable = true)\n",
            " |-- loan_percent_income: string (nullable = true)\n",
            " |-- cb_person_default_on_file: string (nullable = true)\n",
            " |-- cb_person_cred_hist_length: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "credits.createOrReplaceTempView('credits')"
      ],
      "metadata": {
        "id": "HDorKleNG5Er"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select sum(loan_amnt), avg(person_emp_length) from credits where loan_status=1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1nVq-cGHK6O",
        "outputId": "342ac997-c391-4e98-ddb6-54eedddb7fab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------------------+\n",
            "|sum(loan_amnt)|avg(person_emp_length)|\n",
            "+--------------+----------------------+\n",
            "|   7.7125375E7|     4.137562261939642|\n",
            "+--------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "credits.where((credits.loan_status==1)).agg({'loan_amnt':'sum', 'person_emp_length':'mean'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBpl6j2eHm2G",
        "outputId": "e2e581ee-458d-4024-a989-8c4ccd5c2b08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+--------------+\n",
            "|avg(person_emp_length)|sum(loan_amnt)|\n",
            "+----------------------+--------------+\n",
            "|     4.137562261939642|   7.7125375E7|\n",
            "+----------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select nbr/total *100, loan_status from (select count(*) as nbr, loan_status from credits group by loan_status), (select count(*) as total from credits)').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD9c44jZIiQo",
        "outputId": "7572a223-a6cc-4e97-8b31-fa36653b3c15"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----------+\n",
            "|((nbr / total) * 100)|loan_status|\n",
            "+---------------------+-----------+\n",
            "|    78.18360394094718|          0|\n",
            "|   21.816396059052824|          1|\n",
            "+---------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = spark.sql(\"select count(*) as total from credits\")\n",
        "nbr = spark.sql(\"select count(*) as nbr, loan_status from credits group by loan_status\")\n"
      ],
      "metadata": {
        "id": "ZkMQQVDWJtPN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total.join(nbr).createOrReplaceTempView('temp')\n",
        "spark.sql(\"select nbr/total*100, loan_status from temp\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0mzwUTJJ_Vv",
        "outputId": "85737405-7b96-4eec-fdd2-15869abcc37e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----------+\n",
            "|((nbr / total) * 100)|loan_status|\n",
            "+---------------------+-----------+\n",
            "|    78.18360394094718|          0|\n",
            "|   21.816396059052824|          1|\n",
            "+---------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}